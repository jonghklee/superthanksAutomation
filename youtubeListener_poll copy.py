import time
import requests
from sendSuperThanks import process_super_thanks
import csv
from pathlib import Path
import concurrent.futures
import atexit
from threading import Event, Lock, RLock
from bs4 import BeautifulSoup
import re
import logging
import json
import os
import subprocess
from datetime import datetime
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import threading
import sys
from collections import defaultdict
import multiprocessing

isTest = 3
Ticket = 100

# ì†¡ê¸ˆ ì™„ë£Œëœ ì˜ìƒ ì¶”ì ì„ ìœ„í•œ íŒŒì¼ ê²½ë¡œ
COMPLETED_VIDEOS_FILE = "completed_videos.json"

# ì±„ë„ë³„ íƒ€ì„ì•„ì›ƒ ì‹¤íŒ¨ íšŸìˆ˜ ì¶”ì  (ìŠ¤ë ˆë“œ ì•ˆì „)
channel_timeout_failures = defaultdict(int)
channel_timeout_lock = RLock()

# ì™„ë£Œëœ ì˜ìƒ ì¶”ì  (ìŠ¤ë ˆë“œ ì•ˆì „)
completed_videos_cache = {}
completed_videos_lock = RLock()

# ë§ˆì§€ë§‰ ì˜ìƒ ID ì¶”ì  (ìŠ¤ë ˆë“œ ì•ˆì „)
last_video_ids_lock = RLock()

# Free Threading ì„¤ì •
FREE_THREADING_ENABLED = not hasattr(sys, '_getframe') or getattr(sys, 'flags', None) and hasattr(sys.flags, 'disable_gil')
MAX_WORKERS = min(50, (multiprocessing.cpu_count() * 4)) if FREE_THREADING_ENABLED else min(20, multiprocessing.cpu_count() * 2)

print(f"ğŸš€ Free Threading ìƒíƒœ: {'í™œì„±í™”' if FREE_THREADING_ENABLED else 'ë¹„í™œì„±í™”'}")
print(f"ğŸ”§ ìµœëŒ€ ì›Œì»¤ ìˆ˜: {MAX_WORKERS}")
print(f"ğŸ’» CPU ì½”ì–´ ìˆ˜: {multiprocessing.cpu_count()}")

# ë¡œê±° ìƒì„±
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# ì½˜ì†” í•¸ë“¤ëŸ¬
console_handler = logging.StreamHandler()
console_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))

# íŒŒì¼ í•¸ë“¤ëŸ¬
file_handler = logging.FileHandler('youtube_listener.log', encoding='utf-8')
file_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S'))

# í•¸ë“¤ëŸ¬ ë“±ë¡
logger.addHandler(console_handler)
logger.addHandler(file_handler)

stop_event = Event()
atexit.register(stop_event.set)

CSV_PATH = Path("./channel_list.csv")
POLL_INTERVAL = 1  # 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ë‹¤ì‹œ ë³€ê²½
last_video_ids = {}

namespaces = {
    'atom': 'http://www.w3.org/2005/Atom',
    'yt': 'http://www.youtube.com/xml/schemas/2015'
}

def capture_screen_on_error(error_info):
    """ì—ëŸ¬ ë°œìƒ ì‹œ í™”ë©´ ìº¡ì²˜"""
    try:
        # captures í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists("captures"):
            os.makedirs("captures")
        
        # í˜„ì¬ ì‹œê°„ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        capture_filename = f"captures/error_{timestamp}.png"
        
        # macOSì—ì„œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        result = subprocess.run(["screencapture", "-x", capture_filename], capture_output=True)
        
        if result.returncode == 0 and os.path.exists(capture_filename):
            abs_path = os.path.abspath(capture_filename)
            logger.error(f"ğŸ“¸ ì—ëŸ¬ ë°œìƒìœ¼ë¡œ ì¸í•œ í™”ë©´ ìº¡ì²˜ ì €ì¥ë¨: {abs_path}")
            logger.error(f"ğŸ”— íŒŒì¼ ë§í¬: file://{abs_path}")
            return abs_path
        else:
            logger.error("âŒ í™”ë©´ ìº¡ì²˜ ì €ì¥ ì‹¤íŒ¨")
            return None
            
    except Exception as e:
        logger.error(f"âŒ í™”ë©´ ìº¡ì²˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def load_completed_videos():
    """ì™„ë£Œëœ ì˜ìƒ ëª©ë¡ ë¡œë“œ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    with completed_videos_lock:
        # ìºì‹œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë°˜í™˜
        if completed_videos_cache:
            return completed_videos_cache.copy()
        
        try:
            if os.path.exists(COMPLETED_VIDEOS_FILE):
                with open(COMPLETED_VIDEOS_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    completed_videos_cache.update(data)
                    return data
            return {}
        except Exception as e:
            logger.error(f"ì™„ë£Œëœ ì˜ìƒ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

def save_completed_video(channel_id, video_id, video_title=""):
    """ì™„ë£Œëœ ì˜ìƒ ì •ë³´ ì €ì¥ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    with completed_videos_lock:
        try:
            # ìºì‹œ ì—…ë°ì´íŠ¸
            if channel_id not in completed_videos_cache:
                completed_videos_cache[channel_id] = {}
            
            completed_videos_cache[channel_id][video_id] = {
                "title": video_title,
                "completed_at": datetime.now().isoformat(),
                "timestamp": int(time.time())
            }
            
            # íŒŒì¼ ì €ì¥
            with open(COMPLETED_VIDEOS_FILE, 'w', encoding='utf-8') as f:
                json.dump(completed_videos_cache, f, ensure_ascii=False, indent=2)
            
            logger.info(f"[{channel_id}] ì†¡ê¸ˆ ì™„ë£Œ ì˜ìƒ ì €ì¥: {video_id}")
            
        except Exception as e:
            logger.error(f"ì™„ë£Œëœ ì˜ìƒ ì €ì¥ ì‹¤íŒ¨: {e}")

def is_video_completed(channel_id, video_id):
    """ì˜ìƒì´ ì´ë¯¸ ì†¡ê¸ˆ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    with completed_videos_lock:
        try:
            # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
            if channel_id in completed_videos_cache:
                return video_id in completed_videos_cache[channel_id]
            
            # ìºì‹œì— ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ
            completed = load_completed_videos()
            return video_id in completed.get(channel_id, {})
        except Exception as e:
            logger.error(f"ì™„ë£Œëœ ì˜ìƒ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

def create_fast_session():
    """Free Threading ìµœì í™”ëœ ì„¸ì…˜ ìƒì„±"""
    session = requests.Session()
    
    # Free Threading í™˜ê²½ì—ì„œ ë” ê³µê²©ì ì¸ ì„¤ì •
    retry_strategy = Retry(
        total=2,
        backoff_factor=0.2,  # ë” ë¹ ë¥¸ ì¬ì‹œë„
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS"]
    )
    
    # Free Threadingì—ì„œëŠ” ë” ë§ì€ ì—°ê²° í’€ ì‚¬ìš© ê°€ëŠ¥
    pool_size = 100 if FREE_THREADING_ENABLED else 50
    adapter = HTTPAdapter(
        max_retries=retry_strategy, 
        pool_connections=pool_size, 
        pool_maxsize=pool_size,
        socket_options=[(41, 1, 1)]  # TCP_NODELAY ì„¤ì •
    )
    
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': 'no-cache',
        'DNT': '1'
    })
    
    return session

# ì „ì—­ ì„¸ì…˜ ìƒì„±
session = create_fast_session()

def read_channel_ids():
    ids = []
    if not CSV_PATH.exists():
        return ids
    with open(CSV_PATH, newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            channel_id = row.get('channel_id')
            if channel_id:
                ids.append(channel_id)
    return ids

def read_message():
    message = []
    if not CSV_PATH.exists():
        return message
    with open(CSV_PATH, newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            message.append(row.get('message'))
    return message

def parse_html_content(html_content, channel_id):
    """HTML íŒŒì‹±ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬ (CPU ì§‘ì•½ì  ì‘ì—…)"""
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        scripts = soup.find_all("script")
        for script in scripts:
            if 'var ytInitialData' in script.text:
                initial_data = script.text
                match = re.search(r'"videoId":"(.*?)"', initial_data)
                if match:
                    return match.group(1)
        return None
    except Exception as e:
        logger.warning(f"[{channel_id}] HTML íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

def fetch_and_process(channel_id, mother_executor, message):
    """Free Threading ìµœì í™”ëœ ì±„ë„ í™•ì¸ ë° ì²˜ë¦¬"""
    global isTest, Ticket
    
    try:
        start_time = time.time()
        thread_id = threading.get_ident()
        
        # ìŠ¤ë ˆë“œ ì•ˆì „í•œ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        with channel_timeout_lock:
            failure_count = channel_timeout_failures[channel_id]
            timeout = min(10 + (failure_count * 5), 25)
        
        if failure_count > 0:
            logger.info(f"[{channel_id}] ì ì‘í˜• íƒ€ì„ì•„ì›ƒ: {timeout}ì´ˆ (ì‹¤íŒ¨ íšŸìˆ˜: {failure_count}) [Thread-{thread_id}]")
        
        channel_url = f"https://www.youtube.com/channel/{channel_id}/videos"
        
        response = session.get(channel_url, timeout=timeout)
        
        if response.status_code == 200:
            # ì„±ê³µ ì‹œ íƒ€ì„ì•„ì›ƒ ì‹¤íŒ¨ ì¹´ìš´í„° ë¦¬ì…‹ (ìŠ¤ë ˆë“œ ì•ˆì „)
            with channel_timeout_lock:
                if channel_timeout_failures[channel_id] > 0:
                    logger.info(f"[{channel_id}] ìš”ì²­ ì„±ê³µ - íƒ€ì„ì•„ì›ƒ ì¹´ìš´í„° ë¦¬ì…‹ [Thread-{thread_id}]")
                    channel_timeout_failures[channel_id] = 0
            
            # HTML íŒŒì‹±ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬ (CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³‘ë ¬í™”)
            video_id = parse_html_content(response.text, channel_id)
            
            if video_id:
                # ì¤‘ë³µ ì†¡ê¸ˆ ë°©ì§€ í™•ì¸
                if is_video_completed(channel_id, video_id):
                    logger.info(f"[{channel_id}] ì´ë¯¸ ì†¡ê¸ˆ ì™„ë£Œëœ ì˜ìƒ: {video_id} [Thread-{thread_id}]")
                    return
                
                # ìŠ¤ë ˆë“œ ì•ˆì „í•œ last_video_ids ì ‘ê·¼
                with last_video_ids_lock:
                    is_new_video = last_video_ids.get(channel_id) != video_id or isTest > 0
                    if is_new_video and Ticket > 0:
                        if isTest > 0:
                            isTest -= 1
                        Ticket -= 1
                        logger.info(f"[{channel_id}] ìƒˆ ì˜ìƒ ë°œê²¬! {video_id} [Thread-{thread_id}]")
                        last_video_ids[channel_id] = video_id
                        
                        # ì†¡ê¸ˆ ì‘ì—… ì œì¶œ
                        future = mother_executor.submit(process_super_thanks, video_id, logger, message)
                        
                        # ì†¡ê¸ˆ ì™„ë£Œ í›„ ê¸°ë¡ (ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì½œë°± ì¶”ê°€)
                        def mark_completed(fut):
                            try:
                                save_completed_video(channel_id, video_id)
                            except Exception as e:
                                logger.error(f"ì†¡ê¸ˆ ì™„ë£Œ ê¸°ë¡ ì‹¤íŒ¨: {e}")
                        
                        future.add_done_callback(mark_completed)
        else:
            logger.warning(f"[{channel_id}] í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            
        elapsed = time.time() - start_time
        logger.debug(f"[{channel_id}] í™•ì¸ ì™„ë£Œ ({elapsed:.2f}ì´ˆ)")
        
    except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:
        # ìŠ¤ë ˆë“œ ì•ˆì „í•œ íƒ€ì„ì•„ì›ƒ ì‹¤íŒ¨ ì¹´ìš´í„° ì¦ê°€
        if isinstance(e, requests.exceptions.Timeout):
            with channel_timeout_lock:
                channel_timeout_failures[channel_id] += 1
                failure_count = channel_timeout_failures[channel_id]
            logger.warning(f"[{channel_id}] íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ (ì‹¤íŒ¨ íšŸìˆ˜: {failure_count}) - ë‹¤ìŒ ì‹œë„ì—ì„œ íƒ€ì„ì•„ì›ƒ ì¦ê°€ [Thread-{thread_id}]")
        else:
            logger.warning(f"[{channel_id}] ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {type(e).__name__} [Thread-{thread_id}]")
        
        # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ìº¡ì²˜ (íƒ€ì„ì•„ì›ƒì€ ë„ˆë¬´ ìì£¼ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œì™¸)
        if not isinstance(e, requests.exceptions.Timeout):
            capture_screen_on_error(f"Network error for channel {channel_id}: {e}")
        
    except Exception as e:
        logger.error(f"[{channel_id}] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ [Thread-{thread_id}]", exc_info=True)
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ì‹œ ìº¡ì²˜
        capture_screen_on_error(f"Unexpected error for channel {channel_id}: {e}")

def initialize_last_video_ids():
    """Free Threading ìµœì í™”ëœ ì´ˆê¸°í™”"""
    global last_video_ids
    channel_ids = read_channel_ids()
    
    logger.info(f"ì´ {len(channel_ids)}ê°œ ì±„ë„ ì´ˆê¸°í™” ì‹œì‘... (Free Threading: {'í™œì„±í™”' if FREE_THREADING_ENABLED else 'ë¹„í™œì„±í™”'})")
    
    # Free Threadingì—ì„œëŠ” ë” ë§ì€ ì›Œì»¤ ì‚¬ìš© ê°€ëŠ¥
    init_workers = min(MAX_WORKERS, len(channel_ids))
    logger.info(f"ì´ˆê¸°í™” ì›Œì»¤ ìˆ˜: {init_workers}")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=init_workers) as executor:
        futures = []
        
        def init_channel(channel_id):
            try:
                thread_id = threading.get_ident()
                channel_url = f"https://www.youtube.com/channel/{channel_id}/videos"
                response = session.get(channel_url, timeout=10)
                
                if response.status_code == 200:
                    # HTML íŒŒì‹±ì„ ë³„ë„ í•¨ìˆ˜ ì‚¬ìš© (CPU ì§‘ì•½ì  ì‘ì—…)
                    video_id = parse_html_content(response.text, channel_id)
                    if video_id:
                        # ìŠ¤ë ˆë“œ ì•ˆì „í•œ last_video_ids ì—…ë°ì´íŠ¸
                        with last_video_ids_lock:
                            last_video_ids[channel_id] = video_id
                        logger.info(f"[{channel_id}] ì´ˆê¸°í™” ì™„ë£Œ: {video_id} [Thread-{thread_id}]")
            except Exception as e:
                logger.warning(f"[{channel_id}] ì´ˆê¸°í™” ì‹¤íŒ¨: {e} [Thread-{threading.get_ident()}]")
        
        # ëª¨ë“  ì±„ë„ì— ëŒ€í•´ ì´ˆê¸°í™” ì‘ì—… ì œì¶œ
        for channel_id in channel_ids:
            future = executor.submit(init_channel, channel_id)
            futures.append(future)
        
        # ëª¨ë“  ì´ˆê¸°í™” ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
        concurrent.futures.wait(futures, timeout=30)
    
    logger.info(f"ì´ˆê¸°í™” ì™„ë£Œ: {len(last_video_ids)}ê°œ ì±„ë„")

def poll_feed():
    """Free Threading ìµœì í™”ëœ í”¼ë“œ í´ë§ - 1ë¶„ ì•ˆì— 100ê°œ ì±„ë„ í™•ì¸"""
    global last_video_ids
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as mother_executor:
        try:
            cycle_count = 0
            while not stop_event.is_set() and Ticket > 0:
                try:
                    cycle_count += 1
                    cycle_start = time.time()
                    logger.info(f"[=== í”¼ë“œ ì²´í¬ ì‚¬ì´í´ #{cycle_count} ì‹œì‘ ===]")
                    logger.info(f"Free Threading: {'í™œì„±í™”' if FREE_THREADING_ENABLED else 'ë¹„í™œì„±í™”'}, ìµœëŒ€ ì›Œì»¤: {MAX_WORKERS}")
                    
                    channel_ids = read_channel_ids()
                    messages = read_message()
                    
                    logger.info(f"í™•ì¸í•  ì±„ë„ ìˆ˜: {len(channel_ids)}ê°œ, ë‚¨ì€ í‹°ì¼“: {Ticket}")
                    
                    # Free Threadingì—ì„œëŠ” ë” ë§ì€ ì›Œì»¤ ì‚¬ìš©
                    poll_workers = min(MAX_WORKERS, len(channel_ids))
                    with concurrent.futures.ThreadPoolExecutor(max_workers=poll_workers) as executor:
                        futures = []
                        
                        for i, channel_id in enumerate(channel_ids):
                            message = messages[i] if i < len(messages) else ""
                            future = executor.submit(fetch_and_process, channel_id, mother_executor, message)
                            futures.append(future)
                        
                        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 50ì´ˆ)
                        completed_futures = concurrent.futures.wait(futures, timeout=50)
                        
                        # ì™„ë£Œë˜ì§€ ì•Šì€ ì‘ì—… í™•ì¸
                        not_done = len(completed_futures.not_done)
                        done = len(completed_futures.done)
                        if not_done > 0:
                            logger.warning(f"âš ï¸ {not_done}ê°œ ì±„ë„ í™•ì¸ì´ ì‹œê°„ ì´ˆê³¼ë¡œ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (ì™„ë£Œ: {done}ê°œ)")
                    
                    cycle_elapsed = time.time() - cycle_start
                    channels_per_second = len(channel_ids) / cycle_elapsed if cycle_elapsed > 0 else 0
                    logger.info(f"[=== ì‚¬ì´í´ #{cycle_count} ì™„ë£Œ: {cycle_elapsed:.2f}ì´ˆ, {channels_per_second:.1f} ì±„ë„/ì´ˆ ===]")
                    
                    # 1ë¶„ ì‚¬ì´í´ ë§ì¶”ê¸° ìœ„í•œ ëŒ€ê¸°
                    if cycle_elapsed < 60:
                        wait_time = 60 - cycle_elapsed
                        logger.info(f"ë‹¤ìŒ ì‚¬ì´í´ê¹Œì§€ {wait_time:.1f}ì´ˆ ëŒ€ê¸°...")
                        time.sleep(wait_time)
                    
                except Exception as e:
                    logger.error("[í”¼ë“œ ì „ì²´ ì˜¤ë¥˜]", exc_info=True)
                    # ì „ì²´ ì˜¤ë¥˜ ì‹œ ìº¡ì²˜
                    capture_screen_on_error(f"Feed polling error: {e}")
                    time.sleep(5)  # ì˜¤ë¥˜ ì‹œ 5ì´ˆ ëŒ€ê¸°
                    
        except KeyboardInterrupt:
            logger.warning("ì‚¬ìš©ì ì¸í„°ëŸ½íŠ¸ - ì‘ì—… ì·¨ì†Œ ì‹œë„")
            mother_executor.shutdown(wait=False, cancel_futures=True)
            raise
        finally:
            # ì„¸ì…˜ ì¢…ë£Œ
            session.close()

if __name__ == '__main__':
    logger.info("")
    logger.info("=" * 50)
    logger.info("------- í”„ë¡œê·¸ë¨ ì‹œì‘ -------")
    logger.info("=" * 50)
    logger.info(f"isTest: {isTest}, Ticket: {Ticket}")
    logger.info("ë¹ ë¥¸ ì´ˆê¸°í™” ì¤‘...")
    
    try:
        initialize_last_video_ids()
        logger.info("ì´ˆê¸°í™” ì™„ë£Œ - í”¼ë“œ í´ë§ ì‹œì‘")
        poll_feed()
    except Exception as e:
        logger.error("í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", exc_info=True)
        capture_screen_on_error(f"Program startup error: {e}")