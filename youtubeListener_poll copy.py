import time
import requests
from sendSuperThanks import process_super_thanks
import csv
from pathlib import Path
import concurrent.futures
import atexit
from threading import Event
from bs4 import BeautifulSoup
import re
import logging
import json
import os
import subprocess
from datetime import datetime
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

isTest = 3
Ticket = 100

# ì†¡ê¸ˆ ì™„ë£Œëœ ì˜ìƒ ì¶”ì ì„ ìœ„í•œ íŒŒì¼ ê²½ë¡œ
COMPLETED_VIDEOS_FILE = "completed_videos.json"

# ë¡œê±° ìƒì„±
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# ì½˜ì†” í•¸ë“¤ëŸ¬
console_handler = logging.StreamHandler()
console_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))

# íŒŒì¼ í•¸ë“¤ëŸ¬
file_handler = logging.FileHandler('youtube_listener.log', encoding='utf-8')
file_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S'))

# í•¸ë“¤ëŸ¬ ë“±ë¡
logger.addHandler(console_handler)
logger.addHandler(file_handler)

stop_event = Event()
atexit.register(stop_event.set)

CSV_PATH = Path("./channel_list.csv")
POLL_INTERVAL = 1  # 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ë‹¤ì‹œ ë³€ê²½
last_video_ids = {}

# ì±„ë„ë³„ íƒ€ì„ì•„ì›ƒ ì‹¤íŒ¨ íšŸìˆ˜ ì¶”ì 
channel_timeout_failures = {}

namespaces = {
    'atom': 'http://www.w3.org/2005/Atom',
    'yt': 'http://www.youtube.com/xml/schemas/2015'
}

def capture_screen_on_error(error_info):
    """ì—ëŸ¬ ë°œìƒ ì‹œ í™”ë©´ ìº¡ì²˜"""
    try:
        # captures í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists("captures"):
            os.makedirs("captures")
        
        # í˜„ì¬ ì‹œê°„ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        capture_filename = f"captures/error_{timestamp}.png"
        
        # macOSì—ì„œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        result = subprocess.run(["screencapture", "-x", capture_filename], capture_output=True)
        
        if result.returncode == 0 and os.path.exists(capture_filename):
            abs_path = os.path.abspath(capture_filename)
            logger.error(f"ğŸ“¸ ì—ëŸ¬ ë°œìƒìœ¼ë¡œ ì¸í•œ í™”ë©´ ìº¡ì²˜ ì €ì¥ë¨: {abs_path}")
            logger.error(f"ğŸ”— íŒŒì¼ ë§í¬: file://{abs_path}")
            return abs_path
        else:
            logger.error("âŒ í™”ë©´ ìº¡ì²˜ ì €ì¥ ì‹¤íŒ¨")
            return None
            
    except Exception as e:
        logger.error(f"âŒ í™”ë©´ ìº¡ì²˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def load_completed_videos():
    """ì™„ë£Œëœ ì˜ìƒ ëª©ë¡ ë¡œë“œ"""
    try:
        if os.path.exists(COMPLETED_VIDEOS_FILE):
            with open(COMPLETED_VIDEOS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    except Exception as e:
        logger.error(f"ì™„ë£Œëœ ì˜ìƒ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

def save_completed_video(channel_id, video_id, video_title=""):
    """ì™„ë£Œëœ ì˜ìƒ ì •ë³´ ì €ì¥"""
    try:
        completed = load_completed_videos()
        if channel_id not in completed:
            completed[channel_id] = {}
        
        completed[channel_id][video_id] = {
            "title": video_title,
            "completed_at": datetime.now().isoformat(),
            "timestamp": int(time.time())
        }
        
        with open(COMPLETED_VIDEOS_FILE, 'w', encoding='utf-8') as f:
            json.dump(completed, f, ensure_ascii=False, indent=2)
        
        logger.info(f"[{channel_id}] ì†¡ê¸ˆ ì™„ë£Œ ì˜ìƒ ì €ì¥: {video_id}")
        
    except Exception as e:
        logger.error(f"ì™„ë£Œëœ ì˜ìƒ ì €ì¥ ì‹¤íŒ¨: {e}")

def is_video_completed(channel_id, video_id):
    """ì˜ìƒì´ ì´ë¯¸ ì†¡ê¸ˆ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    try:
        completed = load_completed_videos()
        return video_id in completed.get(channel_id, {})
    except Exception as e:
        logger.error(f"ì™„ë£Œëœ ì˜ìƒ í™•ì¸ ì‹¤íŒ¨: {e}")
        return False

def create_fast_session():
    """ë¹ ë¥¸ ìš”ì²­ì„ ìœ„í•œ ìµœì í™”ëœ ì„¸ì…˜ ìƒì„±"""
    session = requests.Session()
    
    # ë¹ ë¥¸ ì¬ì‹œë„ ì „ëµ - ì‹¤íŒ¨ ì‹œ ë¹ ë¥´ê²Œ í¬ê¸°
    retry_strategy = Retry(
        total=2,  # ì¬ì‹œë„ íšŸìˆ˜ ê°ì†Œ
        backoff_factor=0.3,  # ë¹ ë¥¸ ì¬ì‹œë„
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS"]
    )
    
    adapter = HTTPAdapter(max_retries=retry_strategy, pool_connections=50, pool_maxsize=50)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    # ë¹ ë¥¸ ìš”ì²­ì„ ìœ„í•œ í—¤ë” ì„¤ì •
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    })
    
    return session

# ì „ì—­ ì„¸ì…˜ ìƒì„±
session = create_fast_session()

def read_channel_ids():
    ids = []
    if not CSV_PATH.exists():
        return ids
    with open(CSV_PATH, newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            channel_id = row.get('channel_id')
            if channel_id:
                ids.append(channel_id)
    return ids

def read_message():
    message = []
    if not CSV_PATH.exists():
        return message
    with open(CSV_PATH, newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            message.append(row.get('message'))
    return message

def get_channel_timeout(channel_id):
    """ì±„ë„ë³„ ì ì‘í˜• íƒ€ì„ì•„ì›ƒ ê³„ì‚°"""
    base_timeout = 10  # ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ
    failure_count = channel_timeout_failures.get(channel_id, 0)
    
    # ì‹¤íŒ¨ íšŸìˆ˜ì— ë”°ë¼ íƒ€ì„ì•„ì›ƒ ì¦ê°€ (ìµœëŒ€ 30ì´ˆ)
    adaptive_timeout = min(base_timeout + (failure_count * 5), 30)
    return adaptive_timeout

def fetch_and_process(channel_id, mother_executor, message):
    """ë¹ ë¥¸ ì±„ë„ í™•ì¸ ë° ì²˜ë¦¬"""
    global isTest, Ticket
    
    try:
        start_time = time.time()
        
        # ì ì‘í˜• íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì‹¤íŒ¨í•œ ì±„ë„ì€ ë” ê¸´ íƒ€ì„ì•„ì›ƒ)
        timeout = get_channel_timeout(channel_id)
        failure_count = channel_timeout_failures.get(channel_id, 0)
        
        if failure_count > 0:
            logger.info(f"[{channel_id}] ì ì‘í˜• íƒ€ì„ì•„ì›ƒ ì ìš©: {timeout}ì´ˆ (ì‹¤íŒ¨íšŸìˆ˜: {failure_count})")
        
        channel_url = f"https://www.youtube.com/channel/{channel_id}/videos"
        
        response = session.get(channel_url, timeout=timeout)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            scripts = soup.find_all("script")
            for script in scripts:
                if 'var ytInitialData' in script.text:
                    initial_data = script.text
                    match = re.search(r'"videoId":"(.*?)"', initial_data)
                    if match:
                        video_id = match.group(1)
                        
                        # ì¤‘ë³µ ì†¡ê¸ˆ ë°©ì§€ í™•ì¸
                        if is_video_completed(channel_id, video_id):
                            logger.info(f"[{channel_id}] ì´ë¯¸ ì†¡ê¸ˆ ì™„ë£Œëœ ì˜ìƒ: {video_id}")
                            return
                        
                        if (last_video_ids.get(channel_id) != video_id or isTest > 0) and Ticket > 0:
                            if isTest > 0:
                                isTest -= 1         
                            Ticket -= 1
                            logger.info(f"[{channel_id}] ìƒˆ ì˜ìƒ ë°œê²¬! {video_id}")
                            last_video_ids[channel_id] = video_id
                            
                            # ì†¡ê¸ˆ ì‘ì—… ì œì¶œ
                            future = mother_executor.submit(process_super_thanks, video_id, logger, message)
                            
                            # ì†¡ê¸ˆ ì™„ë£Œ í›„ ê¸°ë¡ (ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì½œë°± ì¶”ê°€)
                            def mark_completed(fut):
                                try:
                                    save_completed_video(channel_id, video_id)
                                except Exception as e:
                                    logger.error(f"ì†¡ê¸ˆ ì™„ë£Œ ê¸°ë¡ ì‹¤íŒ¨: {e}")
                            
                            future.add_done_callback(mark_completed)
                        else:
                            # logger.info(f"[{channel_id}] ìƒˆ ì˜ìƒ ì—†ìŒ({video_id})")
                            pass
                    break
        else:
            logger.warning(f"[{channel_id}] í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
        
        # ì„±ê³µí•˜ë©´ ì‹¤íŒ¨ íšŸìˆ˜ ì´ˆê¸°í™”
        if channel_id in channel_timeout_failures:
            del channel_timeout_failures[channel_id]
            logger.info(f"[{channel_id}] íƒ€ì„ì•„ì›ƒ ì‹¤íŒ¨ ê¸°ë¡ ì´ˆê¸°í™”")
            
        elapsed = time.time() - start_time
        logger.debug(f"[{channel_id}] í™•ì¸ ì™„ë£Œ ({elapsed:.2f}ì´ˆ)")
        
    except requests.exceptions.Timeout as e:
        # íƒ€ì„ì•„ì›ƒ ì‹¤íŒ¨ ì‹œ ì‹¤íŒ¨ íšŸìˆ˜ ì¦ê°€
        channel_timeout_failures[channel_id] = channel_timeout_failures.get(channel_id, 0) + 1
        failure_count = channel_timeout_failures[channel_id]
        logger.warning(f"[{channel_id}] íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ (ì‹¤íŒ¨íšŸìˆ˜: {failure_count}, ë‹¤ìŒ íƒ€ì„ì•„ì›ƒ: {get_channel_timeout(channel_id)}ì´ˆ)")
        # íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ ì‹œ ìº¡ì²˜
        capture_screen_on_error(f"Timeout error for channel {channel_id}: {e}")
        
    except requests.exceptions.ConnectionError as e:
        logger.warning(f"[{channel_id}] ì—°ê²° ì˜¤ë¥˜: {type(e).__name__}")
        # ì—°ê²° ì˜¤ë¥˜ ì‹œ ìº¡ì²˜
        capture_screen_on_error(f"Connection error for channel {channel_id}: {e}")
        
    except Exception as e:
        logger.error(f"[{channel_id}] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ", exc_info=True)
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ì‹œ ìº¡ì²˜
        capture_screen_on_error(f"Unexpected error for channel {channel_id}: {e}")

def initialize_last_video_ids():
    """ë¹ ë¥¸ ì´ˆê¸°í™”"""
    global last_video_ids
    channel_ids = read_channel_ids()
    
    logger.info(f"ì´ {len(channel_ids)}ê°œ ì±„ë„ ì´ˆê¸°í™” ì‹œì‘...")
    
    # ë³‘ë ¬ë¡œ ë¹ ë¥´ê²Œ ì´ˆê¸°í™” (ìµœëŒ€ 20ê°œ ë™ì‹œ ì²˜ë¦¬)
    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        futures = []
        
        def init_channel(channel_id):
            try:
                channel_url = f"https://www.youtube.com/channel/{channel_id}/videos"
                response = session.get(channel_url, timeout=get_channel_timeout(channel_id))
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    scripts = soup.find_all("script")
                    for script in scripts:
                        if 'var ytInitialData' in script.text:
                            initial_data = script.text
                            match = re.search(r'"videoId":"(.*?)"', initial_data)
                            if match:
                                last_video_ids[channel_id] = match.group(1)
                                logger.info(f"[{channel_id}] ì´ˆê¸°í™” ì™„ë£Œ: {match.group(1)}")
                            break
            except Exception as e:
                logger.warning(f"[{channel_id}] ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ëª¨ë“  ì±„ë„ì— ëŒ€í•´ ì´ˆê¸°í™” ì‘ì—… ì œì¶œ
        for channel_id in channel_ids:
            future = executor.submit(init_channel, channel_id)
            futures.append(future)
        
        # ëª¨ë“  ì´ˆê¸°í™” ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
        concurrent.futures.wait(futures, timeout=30)
    
    logger.info(f"ì´ˆê¸°í™” ì™„ë£Œ: {len(last_video_ids)}ê°œ ì±„ë„")

def poll_feed():
    """ìµœì í™”ëœ í”¼ë“œ í´ë§ - 1ë¶„ ì•ˆì— 100ê°œ ì±„ë„ í™•ì¸"""
    global last_video_ids
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as mother_executor:
        try:
            while not stop_event.is_set() and Ticket > 0:
                try:
                    cycle_start = time.time()
                    logger.info("[=== í”¼ë“œ ì²´í¬ ì‚¬ì´í´ ì‹œì‘ ===]")
                    
                    channel_ids = read_channel_ids()
                    messages = read_message()
                    
                    logger.info(f"í™•ì¸í•  ì±„ë„ ìˆ˜: {len(channel_ids)}ê°œ")
                    
                    # ìµœëŒ€ 20ê°œ ì±„ë„ì„ ë™ì‹œì— ì²˜ë¦¬ (100ê°œ ì±„ë„ì„ 50ì´ˆ ì•ˆì— ì²˜ë¦¬í•˜ê¸° ìœ„í•´)
                    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
                        futures = []
                        
                        for i, channel_id in enumerate(channel_ids):
                            message = messages[i] if i < len(messages) else ""
                            future = executor.submit(fetch_and_process, channel_id, mother_executor, message)
                            futures.append(future)
                        
                        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 50ì´ˆ)
                        completed_futures = concurrent.futures.wait(futures, timeout=50)
                        
                        # ì™„ë£Œë˜ì§€ ì•Šì€ ì‘ì—… í™•ì¸
                        not_done = len(completed_futures.not_done)
                        if not_done > 0:
                            logger.warning(f"âš ï¸ {not_done}ê°œ ì±„ë„ í™•ì¸ì´ ì‹œê°„ ì´ˆê³¼ë¡œ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                    
                    cycle_elapsed = time.time() - cycle_start
                    logger.info(f"[=== í”¼ë“œ ì²´í¬ ì‚¬ì´í´ ì™„ë£Œ: {cycle_elapsed:.2f}ì´ˆ ===]")
                    
                    # 1ë¶„ ì‚¬ì´í´ ë§ì¶”ê¸° ìœ„í•œ ëŒ€ê¸°
                    if cycle_elapsed < 60:
                        wait_time = 60 - cycle_elapsed
                        logger.info(f"ë‹¤ìŒ ì‚¬ì´í´ê¹Œì§€ {wait_time:.1f}ì´ˆ ëŒ€ê¸°...")
                        time.sleep(wait_time)
                    
                except Exception as e:
                    logger.error("[í”¼ë“œ ì „ì²´ ì˜¤ë¥˜]", exc_info=True)
                    # ì „ì²´ ì˜¤ë¥˜ ì‹œ ìº¡ì²˜
                    capture_screen_on_error(f"Feed polling error: {e}")
                    time.sleep(5)  # ì˜¤ë¥˜ ì‹œ 5ì´ˆ ëŒ€ê¸°
                    
        except KeyboardInterrupt:
            logger.warning("ì‚¬ìš©ì ì¸í„°ëŸ½íŠ¸ - ì‘ì—… ì·¨ì†Œ ì‹œë„")
            mother_executor.shutdown(wait=False, cancel_futures=True)
            raise
        finally:
            # ì„¸ì…˜ ì¢…ë£Œ
            session.close()

if __name__ == '__main__':
    logger.info("")
    logger.info("=" * 50)
    logger.info("------- í”„ë¡œê·¸ë¨ ì‹œì‘ -------")
    logger.info("=" * 50)
    logger.info(f"isTest: {isTest}, Ticket: {Ticket}")
    logger.info("ë¹ ë¥¸ ì´ˆê¸°í™” ì¤‘...")
    
    try:
        initialize_last_video_ids()
        logger.info("ì´ˆê¸°í™” ì™„ë£Œ - í”¼ë“œ í´ë§ ì‹œì‘")
        poll_feed()
    except Exception as e:
        logger.error("í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", exc_info=True)
        capture_screen_on_error(f"Program startup error: {e}")